# 123sourcing - Document Processing & OCR API

API de extracci√≥n de datos y detecci√≥n de sellos usando PaddleOCR, LayoutLM/Ernie Layout y Pinecone Vector Database.

---

## üìã Descripci√≥n del Proyecto

Este proyecto Django proporciona APIs para:
- **Extracci√≥n de datos** de documentos PDF e im√°genes (shipmentId, deliveryId)
- **Detecci√≥n y verificaci√≥n de sellos** usando embeddings vectoriales
- **Almacenamiento de sellos** en Pinecone Vector Database

**Tecnolog√≠as:** Django 4.2, PaddleOCR, Transformers (LayoutLM), Pinecone, MySQL

---

## üöÄ Configuraci√≥n Local (CPU)

### Requisitos Previos
- Python 3.9+ (recomendado 3.10)
- MySQL 5.7+
- 8GB RAM m√≠nimo (16GB recomendado)
- 20GB de espacio en disco

### Setup Autom√°tico

```bash
# 1. Clonar el repositorio
git clone https://github.com/LissomR/123sourcing.git
cd 123sourcing

# 2. Ejecutar script de setup
./setup_local.sh
```

El script autom√°ticamente:
- ‚úÖ Crea entorno virtual
- ‚úÖ Instala dependencias CPU
- ‚úÖ Descarga modelos entrenados
- ‚úÖ Configura base de datos MySQL
- ‚úÖ Crea archivo .env

### Setup Manual

```bash
# 1. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# 2. Instalar dependencias
pip install -r requirements.cpu.txt

# 3. Configurar variables de entorno
cp .env.example api_channel/.env
# Editar api_channel/.env con tus credenciales

# 4. Descargar modelos
./download_models.sh

# 5. Configurar MySQL
mysql -u root -p
```

```sql
CREATE DATABASE 123sourcing_db CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
CREATE USER '123sourcing_user'@'localhost' IDENTIFIED BY 'tu_password';
GRANT ALL PRIVILEGES ON 123sourcing_db.* TO '123sourcing_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;
```

```bash
# Importar schema
mysql -u 123sourcing_user -p 123sourcing_db < MySql.sql

# 6. Ejecutar migraciones
python manage.py migrate

# 7. Crear superusuario (opcional)
python manage.py createsuperuser

# 8. Iniciar servidor
python manage.py runserver
```

### Variables de Entorno Requeridas

Editar `api_channel/.env`:

```env
# Django
DJANGO_SECRET_KEY='tu-secret-key-aqui'
DJANGO_DATABASE_SERVER=localhost
DJANGO_DATABASE_NAME=123sourcing_db
DJANGO_DATABASE_USER=123sourcing_user
DJANGO_DATABASE_PASSWORD=tu_password
AUTH_TOKEN_EXPIRE_TIME=1440
JWT_AUTH_SECRET=tu-jwt-secret

# Server
HOST_SERVER_URL=http://localhost:8000

# Pinecone (obtener desde https://www.pinecone.io/)
PINECONE_API_KEY=tu-pinecone-api-key
PINECONE_INDEX_NAME=image-stamp-index

# Paths
MODELS_PATH=trained_models
TOKENIZERS_PARALLELISM=false
```

---

## ‚òÅÔ∏è Deploy en Railway

### Paso 1: Configurar Pinecone

1. Crear cuenta en [Pinecone](https://www.pinecone.io/)
2. Crear un nuevo √≠ndice:
   - Nombre: `image-stamp-index`
   - Dimensiones: 768
   - Metric: cosine
3. Copiar tu API key

### Paso 2: Configurar MySQL en Railway

```bash
# Instalar Railway CLI
npm i -g @railway/cli

# Login
railway login

# Crear proyecto
railway init
```

En Railway Dashboard:
1. A√±adir servicio **MySQL**
2. Copiar las credenciales de conexi√≥n

### Paso 3: Deploy del Proyecto

```bash
# Conectar con Railway
railway link

# Configurar variables de entorno
railway variables set DJANGO_SECRET_KEY="tu-secret-key"
railway variables set PINECONE_API_KEY="tu-api-key"
railway variables set PINECONE_INDEX_NAME="image-stamp-index"
railway variables set DJANGO_DATABASE_SERVER="${{MySQL.MYSQL_HOST}}"
railway variables set DJANGO_DATABASE_NAME="${{MySQL.MYSQL_DATABASE}}"
railway variables set DJANGO_DATABASE_USER="${{MySQL.MYSQL_USER}}"
railway variables set DJANGO_DATABASE_PASSWORD="${{MySQL.MYSQL_PASSWORD}}"
railway variables set JWT_AUTH_SECRET="tu-jwt-secret"
railway variables set AUTH_TOKEN_EXPIRE_TIME="1440"
railway variables set MODELS_PATH="trained_models"
railway variables set TOKENIZERS_PARALLELISM="false"

# Deploy
railway up
```

**Nota:** Railway usar√° `Dockerfile.railway` que est√° optimizado para CPU.

### Paso 4: Importar Schema de BD

```bash
# Conectar a MySQL de Railway
railway connect MySQL

# En el cliente MySQL
SOURCE MySql.sql;
```

### Alternativa: Deploy desde GitHub

1. Conecta tu repositorio GitHub en Railway Dashboard
2. Configura las variables de entorno en Settings
3. Railway detectar√° autom√°ticamente el `Dockerfile.railway`
4. Deploy autom√°tico en cada push

---

## üìö API Documentation

### Autenticaci√≥n

Todas las APIs requieren un Bearer token en el header:

```http
Authorization: Bearer YOUR_TOKEN_HERE
```

### API 1: Add Stamp

Agregar imagen de sello a Pinecone Vector Database.

**Endpoint:** `POST /AddStamp`

**Par√°metros:**
- `files` (form-data): Archivo de imagen
- `url` (text): URL de imagen (alternativa a files)
- `companyId` (text, requerido): ID √∫nico de la compa√±√≠a

**Ejemplo:**
```bash
curl -X POST https://tu-app.railway.app/AddStamp \
  -H "Authorization: Bearer TOKEN" \
  -F "companyId=e228f6c6-57f1-33ac-bbf5-2720de811e2c" \
  -F "url=https://example.com/stamp.png"
```

### API 2: Data Extraction

Extraer informaci√≥n de documentos (shipmentId, deliveryId).

**Endpoint:** `POST /GetDetails`

**Par√°metros:**
- `files` (form-data): PDF o imagen
- `url` (text): URL del documento (alternativa)
- `bool_stamp_detection` (query): true/false para incluir detecci√≥n de sellos

**Formatos soportados:**
- Im√°genes: .jpeg, .jpg, .png, .gif, .bmp, .webp
- Documentos: .pdf

**Ejemplo:**
```bash
curl -X POST "https://tu-app.railway.app/GetDetails?bool_stamp_detection=true" \
  -H "Authorization: Bearer TOKEN" \
  -F "url=https://example.com/document.pdf"
```

### API 3: Stamp Verification

Verificar presencia de sello en documento.

**Endpoint:** `POST /StampVerification`

**Par√°metros:**
- `files` (form-data): Archivo de imagen
- `url` (text): URL de imagen (alternativa)
- `companyId` (text, requerido): ID a verificar

**Ejemplo:**
```bash
curl -X POST https://tu-app.railway.app/StampVerification \
  -H "Authorization: Bearer TOKEN" \
  -F "companyId=e228f6c6-57f1-33ac-bbf5-2720de811e2c" \
  -F "files=@document.png"
```

### Swagger Documentation

Acceder a: `https://tu-app.railway.app/swagger`

---

## üèóÔ∏è Arquitectura del Proyecto

```
123sourcing/
‚îú‚îÄ‚îÄ api_channel/          # Configuraci√≥n Django
‚îÇ   ‚îú‚îÄ‚îÄ settings.py       # Settings principal
‚îÇ   ‚îú‚îÄ‚îÄ urls.py          # URLs del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ .env             # Variables de entorno
‚îú‚îÄ‚îÄ custom_lib/          # Librer√≠as personalizadas
‚îÇ   ‚îú‚îÄ‚îÄ authentication.py # Sistema de autenticaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ helper.py        # Funciones auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ logger.py        # Sistema de logging
‚îú‚îÄ‚îÄ data_extraction/     # App de extracci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ paddleocr.py    # Integraci√≥n PaddleOCR
‚îÇ   ‚îú‚îÄ‚îÄ services.py     # L√≥gica de negocio
‚îÇ   ‚îî‚îÄ‚îÄ views.py        # APIs endpoints
‚îú‚îÄ‚îÄ stamp_detection/     # App de detecci√≥n de sellos
‚îÇ   ‚îú‚îÄ‚îÄ pinecone.py     # Integraci√≥n Pinecone
‚îÇ   ‚îî‚îÄ‚îÄ services.py     # L√≥gica de sellos
‚îú‚îÄ‚îÄ users/              # App de usuarios
‚îú‚îÄ‚îÄ trained_models/     # Modelos ML (no en git)
‚îú‚îÄ‚îÄ requirements.txt    # Deps GPU (producci√≥n original)
‚îú‚îÄ‚îÄ requirements.cpu.txt # Deps CPU (local/Railway)
‚îú‚îÄ‚îÄ Dockerfile          # Docker GPU
‚îú‚îÄ‚îÄ Dockerfile.railway  # Docker CPU para Railway
‚îú‚îÄ‚îÄ setup_local.sh      # Script setup autom√°tico
‚îî‚îÄ‚îÄ download_models.sh  # Script descarga modelos
```

---

## üß™ Testing

```bash
# Ejecutar tests
python manage.py test

# Tests espec√≠ficos
python manage.py test data_extraction
python manage.py test stamp_detection
```

---

## üìä Modelos Usados

### 1. LayoutLM (CPU - Local/Railway)
- Modelo: `impira/layoutlm-document-qa`
- Uso: Extracci√≥n de datos de documentos
- Optimizado para CPU
- [Documentaci√≥n](https://huggingface.co/impira/layoutlm-document-qa)

### 2. Ernie Layout (GPU - Producci√≥n)
- Modelo: PaddleNLP Ernie Layout
- Uso: Extracci√≥n avanzada con GPU
- Requiere GPU 16GB+
- [Documentaci√≥n](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-layout)

### 3. PaddleOCR
- Detecci√≥n y reconocimiento de texto
- Soporta CPU y GPU

---

## üõ†Ô∏è Troubleshooting

### Error: MySQL connection failed
```bash
# Verificar que MySQL est√° corriendo
sudo systemctl status mysql

# Verificar credenciales en .env
cat api_channel/.env | grep DJANGO_DATABASE
```

### Error: Trained models not found
```bash
# Descargar modelos manualmente
./download_models.sh

# O manualmente:
wget https://d2hbdgqvbu3n3g.cloudfront.net/123sourcing/trained_models.zip
unzip trained_models.zip
```

### Error: Pinecone index not found
1. Crear √≠ndice en [Pinecone Console](https://app.pinecone.io/)
2. Actualizar `PINECONE_INDEX_NAME` en `.env`

### Railway: Build timeout
- Los modelos son grandes (~2GB)
- Considera usar Railway Pro para m√°s tiempo de build
- O pre-cachear modelos en Docker image

---

## üìù Notas Importantes

- **CPU vs GPU:** Local y Railway usan CPU (m√°s lento pero m√°s barato)
- **Modelos:** Se descargan autom√°ticamente en primer build (~2GB)
- **Base de datos:** Usar Railway MySQL o servicio externo
- **Pinecone:** Tier gratuito disponible para desarrollo

---

## ü§ù Contribuir

1. Fork el proyecto
2. Crear branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push al branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

---

## üìÑ Licencia

Este proyecto es privado y confidencial.

---

## üìû Soporte

Para preguntas o soporte, contactar al equipo de desarrollo.
